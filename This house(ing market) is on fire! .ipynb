{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# This house(ing market) is on fire! \n",
    "## Using American Community Survey and Zillow data to explore housing affordability for protective service workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "When it comes to buying a house, there is a lot more to consider than just the sticker price. Wages and salaries vary widely across the country, including within specific occupations, as does the share of household income local residents are accustomed to dedicating to housing costs each month. At one extreme, some places with low housing costs might appear to be very affordable, but incomes might also be much lower than elsewhere; at the other extreme, some places that appear to be extremely expensive when looking at prices, might be more manageable as a result of relatively high wages and salaries. By combining [Zillow](www.zillow.com/research/data) data on home values, rents, and historical housing costs burdens with data on incomes by occuption from the United States Census Bureau’s [American Community Survey](https://www.census.gov/programs-surveys/acs/) (ACS), we can compare housing affordability for specific types of workers in different communities across the country. In this example, we estimate the share of a household’s income that goes to a monthly mortgage payment on the median home across the country’s metro areas for two types of workers:\n",
    "* Fire fighting and prevention, and other protective service workers, including supervisors (who we broadly label firefighters),\n",
    "* Law enforecement workers, including supervisors (who we broadly label police officers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will guide you through the steps to load and wrangle Zillow and ACS data to compute the share of monthly income required to buy a typical home for firefighters and police officers across the country using the R programming language.\n",
    "To get started quickly, the code for this tutorial can be found at the following [Github repo]([INSERT%20LINK])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by clearing your environment and setting your options, and calling the following libraries:\n",
    "\n",
    "* plyr: Splitting, applying and combining data\n",
    "* dplyr: Data manipulation\n",
    "* readr: Fast loading of tabular data into R\n",
    "* readxl: Fast loading of Microsoft Excel files into R \n",
    "* reshape2: Transform data between long and wide formats\n",
    "* stringi: Transform strings\n",
    "* datasets: Data set with the names and abbreviations of the 50 states of the United States of America (required only for state-level summary files, see pages 9-10 in the [ACS Summary File Technical Documentation](http://www2.census.gov/programs-surveys/acs/summary_file/2014/documentation/tech_docs/2014_SummaryFile_Tech_Doc.pdf))\n",
    "\n",
    "We call the libraries using a function, pkgTest, which checks whether a particular package is loaded in your environment, and if not, installs it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Preliminaries\n",
    "rm(list=ls())\n",
    "## This function will check if a package is installed, and if not, install it\n",
    "pkgTest <- function(x) {\n",
    "if (!require(x, character.only = TRUE)) {\n",
    "install.packages(x, dep = TRUE)\n",
    "if(!require(x, character.only = TRUE)) stop(\"Package not found\") }\n",
    "}\n",
    "## These lines load the required packages\n",
    "packages <- c(\"plyr\", \"dplyr\", \"readr\", \"readxl\", \"reshape2\", \"stringi\", \"dataset s\")\n",
    "lapply(packages, pkgTest)\n",
    "￼## These lines set several options\n",
    "options(scipen = 999) # Do not print scientific notation \n",
    "options(stringsAsFactors = FALSE) ## Do not load strings as factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Loading incomes and Census geographies from the American Community Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load tables from the [ACS Summary File FTP](http://www2.census.gov/programs- surveys/acs/summary_file/). There are several decisions to make:\n",
    "\n",
    "* Which year of data do you want? ACS data are available starting in 2005 (at the time of this writing, 2014 is the most recent year).\n",
    "* Which Summary File folder do you want? For the 2014 ACS there are three options for the 1-year ACS data and three options for the 5-year ACS data: an All-in-one file, a State tables file, and topic tables. Read section 2.2 of the technical documentation (http://www.census.gov/programs- surveys/acs/technical-documentation/summary-file-documentation.2014.html), titled Summary File Organization, to select the file folder best for your needs. After reading the ACS 2014 Technical Documentation (http://www.census.gov/programs-surveys/acs/technical-documentation/summary- file-documentation.html), we select the 1-year topic tables.\n",
    "* Which sequence, table and line number(s) do you want? Using the Summary File Lookup files (https://www.census.gov/programs-surveys/acs/technical-documentation/summary-file- documentation.html), identify the sequence, table and line numbers associated with the variable you are interested in (available under the section Sequence Number/Table Number Lookup File). For this analysis, we are interested in table B24011, which contains median annual earnings by industry, occupation and class of worker, and is found in sequence 107. Lines 21 and 22 contain the median annual earnings of firefighters and police officers, respectively.\n",
    "* Which geographies do you want? There are two decisions here, both associated with the geographic level you want to analyze. First, you need to select the geographic level required for downloading the appropriate ACS geography, then you need to set the geographic summary level for your analysis.\n",
    "    * If the geographic summary level you are interested in crosses state lines, the data will be contained in the geographic file for the United States. If the geographic summary level you are interested in is fully contained within state lines, the data will be contained in the geographic file for each state. The first table on [page 10](http://www2.census.gov/programs-surveys/acs/summary_file/2014/documentation/tech_docs/2014_SummaryFile_Tech_Doc.pdf) in the ACS Technical Documentation can help you determine which file is right for you. Since our analysis will be at the metropolitan statistical area level, we load the ‘United States’ file. For an example of how to load data for geographies fully contained within state lines - such as cities, Zip codes, school districts, and Congressional districts - see the Appendix below. \n",
    "    * Identify the summary code associated with your geographic level of interest by referring to this [ACS Geographic Summary Level table](https://www.census.gov/geo/maps-data/data/summary_level.html). The Summary Level Code for metro areas is 310."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Part 2.1: Set parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above decisions, set your parameters appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "￼## Set parameters to load ACS data\n",
    "year <- 2014\n",
    "summaryFileFolder <- '1_year_seq_by_state' geoLevelFile <- 'United States' geoSummaryLevel <- 310\n",
    "sequence <- 107\n",
    "tableNumber <- 'B24011'\n",
    "Lines <- c(21, 22)\n",
    "acsDrive <- file.path('http://www2.census.gov',\n",
    "                      'programs-surveys',\n",
    "                      'acs', \n",
    "                      'summary_file', \n",
    "                      as.character(year), 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2.2: Load data tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load the ACS and geography tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load geographies\n",
    "geos <- read_csv(file.path(acsDrive, \n",
    "                           summaryFileFolder, \n",
    "                           gsub(\" \", \"\", geoLevelFile, fixed = TRUE), \n",
    "                           paste0('g', as.character(year), 1, 'us', '.csv')), \n",
    "                 col_names = FALSE)\n",
    "## Load ACS tables\n",
    "temp <- tempfile()\n",
    "path <- file.path(acsDrive, \n",
    "                  summaryFileFolder, \n",
    "                  gsub(\" \", \"\", geoLevelFile, fixed = TRUE), \n",
    "                  paste0(as.character(year), 1, 'us', \n",
    "                         stri_pad_left(sequence, 4, pad = '0'), \n",
    "                         '000', '.zip'))\n",
    "download.file(path, destfile = temp)\n",
    "acs <- read_csv(unz(temp,\n",
    "                    paste0('e', as.character(year), '1', 'us',\n",
    "                           stri_pad_left(sequence, 4, pad = '0'),\n",
    "                           '000', '.txt')),\n",
    "                col_names = FALSE)\n",
    "unlink(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command, which appears several times when loading the data, removes spaces from the geoLevelFile name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsub(\" \", \"\", geoLevelFile, fixed = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarily, the function [stri_pad_left](https://cran.r-project.org/web/packages/stringi/stringi.pdf) takes the sequence number and converts it to a character string of a specified length, padding the string with leading characters (zeros in this case).\n",
    "\n",
    "These two functions are particularly important when loading data for sub-state geographies, as described in the Appendix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2.3: Load variable names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the associated variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Download variable and geography names\n",
    "temp <- tempfile()\n",
    "path <- file.path(acsDrive,\n",
    "                  paste0(as.character(year), \n",
    "                         '_1yr_Summary_FileTemplates', \n",
    "                         '.zip'))\n",
    "download.file(path, temp)\n",
    "## Load variable and geography names\n",
    "acsNames <- read_excel(unzip(temp, \n",
    "                             file.path(\n",
    "                                 paste0(as.character(year),\n",
    "                                        '_1yr_Summary_FileTemplates'), \n",
    "                                 paste0('Seq',\n",
    "                                        as.character(sequence), '.xls'))),\n",
    "                       sheet = 'E')\n",
    "geoNames <- read_excel(unzip(temp,\n",
    "                             paste0(\n",
    "                                 as.character(year),\n",
    "                                 '_',\n",
    "                                 'SFGeoFileTemplate',\n",
    "                                 '.xls')),\n",
    "                       sheet = 1)\n",
    "## Close download link\n",
    "unlink(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2.4: Apply variable names to data tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we reformat the column names and apply them to the data tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Reformat variable and geography names, then apply them to the data tables\n",
    "acsNames <- data.frame(varName = colnames(acsNames), varDesc = t(acsNames[1, ]))\n",
    "￼geoNames <- data.frame(geoName = colnames(geoNames), geoDesc = t(geoNames[1, ]))\n",
    "colnames(acs) <- acsNames$varName\n",
    "colnames(geos) <- geoNames$geoName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2.5: Get rid of data that we don’t need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the table structure in the ACS FTP, we loaded a lot of ACS data that we don’t actually need for this particular analysis, so let’s keep only the variables that we’re planning on using: The geographic identifier(s) and the data variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Keep only variables of interest in ACS data\n",
    "acsVars <- paste(tableNumber, as.character(stri_pad_left(Lines, 3, '0')), sep='_')\n",
    "acs <- acs[, c('STUSAB', 'LOGRECNO', acsVars)]\n",
    "acs$STUSAB <- toupper(acs$STUSAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we loaded a lot of geographies that we do not plan on using for this analysis. Let’s get rid of that data.\n",
    "We should also extract the CBSA Code (an integer code associated with each metro area) from the GEOID field in the geography data. You can learn more about understanding the different geographic levels embedded in GEOIDs by reading this [page](https://www.census.gov/geo/reference/geoidentifiers.html) and selecting “GEOID Structure for Geographic Areas”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Keep only geographies of interest\n",
    "geos <- subset(geos, SUMLEVEL == geoSummaryLevel)\n",
    "geos$CBSACode <- as.integer(substr(geos$GEOID, nchar(geos$GEOID) - 4, nchar(geos$G EOID)))\n",
    "geos <- geos[, c('STUSAB', 'LOGRECNO', 'CBSACode', 'NAME')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 2.6: Merge the ACS data with geographic identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let’s merge the ACS data and the geographic codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Merge geos and acs data\n",
    "incomes <- merge(geos, acs[, c('STUSAB', 'LOGRECNO', acsVars)], by = 'LOGRECNO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataframe, called “incomes,” that contains the median annual earnings for firefighters and police officers for each metro area in 2014. We have successfully loaded and formatted incomes from the ACS and are ready to start loading Zillow data on home values and mortgage rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Loading median home values and mortgage rates from Zillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zillow publishes monthly median home values for a wide range of geographic levels ranging from the country and U.S. states down to the neighborhood and ZIP code. These and other data are regularly updated on the [Zillow Data](http://www.zillow.com/research/data/) page. The median home value (ZHVI) for each geographic level reflects the value of the typical home in each geography, regardless if the home is currently for-sale. It is based on Zillow ‘Zestimates’ of nearly 120 million homes nationwide (as of November 2015). You can read more about how Zillow calculates the median home value and Z estimates [here](http://www.zillow.com/research/zhvi-methodology-6032/), and more about Zillow’s coverage and accuracy [here](http://www.zillow.com/howto/DataCoverageRentZestimateAccuracy.htm).\n",
    "\n",
    "Since the types of homes that transact each month changes, median sale prices tend to be highly volatile due to compositional shifts: For instance, if more condos sell in a given month, and in the next month more mansions sell, then the median sale price will appear to have increased more dramatically over the month than the value of any single home. The ZHVI controls for these compositional changes since it reflects the value of the entire housing stock. However, some researchers prefer median sale or list prices, which are also available on the Zillow Data page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 3.1: Load Zillow data on median home values and mortgage rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load Zillow data on median home values at the metro level. We then reshape the data to allow us to merge them with the ACS data on incomes. Since the ACS data correspond to average incomes in 2014, and the Zillow data are a monthly series, we keep only median home values for months in 2014 and take the average across the 12 months of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load Zillow metro median home values\n",
    "zillow <- read_csv('http://files.zillowstatic.com/research/public/Metro/Metro_Zhvi_AllHomes.csv',\n",
    "                   col_names = TRUE)\n",
    "zillow <- melt(zillow, id=c('RegionID', 'RegionName', 'SizeRank'))\n",
    "zillow <- subset(zillow, substr(variable, 1, 4) == '2014')\n",
    "zillow <- ddply(zillow, .(RegionID, RegionName, SizeRank), summarise,\n",
    "                MedianHomeValue = mean(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load data on mortgage rates. Zillow publishes the average interest rate quoted for a standard 30- year fixed rate mortgage to a borrower with a good credit score (a FICO score of 720 or higher) on a loan with a loan-to-value ratio of 0.8 or less. This is the most common loan product Americans use to buy homes. The data are reported in 15-minute increments throughout the business day (6 am to 5 pm Pacific Time, excluding federal holidays). Interest rates are reported already multiplied by 100 – a mortgage rate of 4.2% is reported as 4.2 rather than 0.042 in the data – so we divide by 100 to facilitate computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mortgageRate <- read_csv('http://files.zillowstatic.com/research/public/MortgageRa teConventionalFixed.csv',\n",
    "                         col_names = TRUE)\n",
    "mortgageRate <- subset(mortgageRate, substr(Date, 1, 4) == '2014')\n",
    "mortgageRate <- ddply(mortgageRate, .(substr(Date, 1, 4)), summarise,\n",
    "avgRate2014 = round(mean(MortgageRateConventionalFixed, na.rm = TRUE)/100, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 3.2: Load a crosswalk between Zillow metro areas and Census metro areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Zillow data include metros with slightly different names than the Census data. A county-level crosswalk between the two naming conventions is available [here](http://files.zillowstatic.com/research/public/CountyCrossWalk_Zillow.csv) (metro areas are composed of groups of counties).\n",
    "For this example, we are only interested in the metro-to-metro crosswalk, not the county-to-metro crosswalk, so we remove county identifiers and remove duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "￼## Load Zillow Metro-CBSA crosswalk\n",
    "metroXW <- read_csv('http://files.zillowstatic.com/research/public/CountyCrossWalk _Zillow.csv',\n",
    "                    col_names = TRUE)\n",
    "metroXW <- metroXW[, c('MetroRegionID_Zillow', 'CBSACode')]\n",
    "metroXW <- metroXW[!duplicated(metroXW),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we merge the crosswalk onto the Zillow data on median home values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Merge Zillow data on median home values with crosswalk\n",
    "zillow <- merge(zillow, metroXW, by.x = 'RegionID', by.y = 'MetroRegionID_Zillow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4: Computing mortgage affordability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the Zillow and ACS data is now fairly straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Merge Zillow and ACS data\n",
    "zillow <- merge(zillow, incomes, by = 'CBSACode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use a [standard formula](http://www.wikihow.com/Calculate-Mortgage-Payments) for computing a monthly loan payment based on the loan amount, the interest rate, and the loan amortization (how long before a borrower will pay off the loan). The formula we use is:\n",
    "\n",
    "$$\n",
    "M = P\\frac{r(1+r)^{n}}{(1+r)^{n}-1}\n",
    "$$\n",
    "\n",
    "where:\n",
    "* M = the monthly payment, in dollars\n",
    "* P = the loan principal, or 80% of the home value in this example (the home value minus the down payment)\n",
    "* r = the monthly interest rate (the annual interest rate divided by 12), and\n",
    "* n = the number of monthly payments (360 for a 30-year loan)\n",
    "\n",
    "To make our code easier to read, we implement this using several parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calculate monthly mortgage payment\n",
    "nperiods <- 360 # mortgage loan term, in months\n",
    "compoundingFactor <- (1 + (mortgageRate$avgRate2014 / 12)) ^ nperiods \n",
    "zillow$monthlyPymt <- (0.8 * zillow$MedianHomeValue) * \n",
    "((mortgageRate$avgRate2014 / 12) * compoundingFactor) / (compoundingFactor - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The share of a household’s income that would go toward a monthly mortgage payment on the median home in a given metro area is then simply the ratio of the monthly mortgage payment and the monthly income (annual income divided by 12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Compute monthly payment relative to income\n",
    "zillow$MortgagePymtToInc_Firefighters <- zillow$monthlyPymt / (zillow$B24011_021 / 12)\n",
    "zillow$MortgagePymtToInc_Police <- zillow$monthlyPymt / (zillow$B24011_022 / 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, in these calculations we made several implicit assumptions. For example, we assume that these households are buying a home with only one income. Many households have two incomes (or more in some rare instances). We also assume the household is buying the median home in the metro area. Some buyers may buy a more or less expensive home. There are many different flavors of mortgage affordability that one could compute, but the basic calculation outlined above provides a reasonable basis for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick examination of the results shows that Kokomo (IN), Lumberton (NC) and Manitowoc (WI) are the most affordable metro areas for firefighters. Under our assumptions, firefighters in these communities would need to spend less than 7% of their monthly income on his or her mortgage to buy the median home. By contrast, places like Ithaca (NY), Columbia (MO) and Beaver Dam (WI) – as well as larger places like San Jose (CA), San Francisco (CA) and Kahului (HI) – appear to be far less affordable for firefighters with mortgage-payment-to-income ratios in excess of 1, largely due to very low incomes. This means that even if a firefighter spent their entire income on their mortgage, they could not afford to buy the median home (again, assuming a single-income household)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head(zillow[order(zillow$MortgagePymtToInc_Firefighters),\n",
    "            c('RegionName', 'B24011_021', 'MedianHomeValue', 'MortgagePymtToInc_Firefighters')], 10) \n",
    "head(zillow[order(-zillow$MortgagePymtToInc_Firefighters),\n",
    "            c('RegionName', 'B24011_021', 'MedianHomeValue', 'MortgagePymtToInc_Fi refighters')], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For police, Battle Creek and Saginaw, Michigan, along with several communities in upstate New York, appear to be the most affordable communities. Under our assumptions, police officers in these communities would need to spend less than 6% of their monthly income on thier mortgage to buy the median home. At the other extreme, Oak Harbor (WA), Honolulu (HI), San Jose (CA) and Santa Fe (NM) appear to be the least affordable places for police officers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head(zillow[order(zillow$MortgagePymtToInc_Police),\n",
    "            c('RegionName', 'B24011_022', 'MedianHomeValue', 'MortgagePymtToInc_Police')], 10) \n",
    "head(zillow[order(-zillow$MortgagePymtToInc_Police),\n",
    "            c('RegionName', 'B24011_022', 'MedianHomeValue', 'MortgagePymtToInc_Police')], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is obviously a lot more one could explore in these data. However, the code described above should allow you to do it yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: Loading ACS Data for Sub-state Geographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data for geographies that are fully contained within state lines requires several modifications to the code example above. Since the ACS FTP file structure uses both full state names (e.g., California) and state abreviations (e.g., CA), we write a loop that loads each state file. Of course, if your analysis requires only geographies in a single state, you can bypass the loop.\n",
    "Here we provide an example of loading city-level median incomes for firefighters and police officers.\n",
    "The first step is to load U.S. state names and abreviations, which are conveniently available in the package, datasets. However, we manually bind a state name and abbreviation for the District of Columbia, which is not included in the package data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load state names and abreviations\n",
    "states <- rbind(data.frame(stateName = state.name, \n",
    "                           stateAbrev = state.abb),\n",
    "                c('District of Columbia', 'DC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set our parameters as before. We set the geoLevelFile parameter to NULL as it will be replaced by state names. We also set the geoSummaryLevel to 160, which corresponds to State-Place. [State-Place](https://www.census.gov/geo/reference/gtc/gtc_place.html) includes cities, boroughs, towns and villages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Set parameters to load ACS data, at the city level\n",
    "year <- 2014\n",
    "summaryFileFolder <- '1_year_seq_by_state' \n",
    "geoLevelFile <- NULL\n",
    "geoSummaryLevel <- 160\n",
    "sequence <- 107\n",
    "tableNumber <- 'B24011'\n",
    "Lines <- c(21, 22)\n",
    "acsDrive <- file.path('http://www2.census.gov',\n",
    "                      'programs-surveys', \n",
    "                      'acs', \n",
    "                      'summary_file', \n",
    "                      as.character(year), \n",
    "                      'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop to load the ACS and geography tables for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load geographies, for sub-state geographies\n",
    "geos <- data.frame()\n",
    "for (i in 1:nrow(states)){\n",
    "    geos_temp <- read_csv(file.path(acsDrive, \n",
    "                                    summaryFileFolder,\n",
    "                                    gsub(\" \", \"\", states$stateName[i], fixed = TRUE), \n",
    "                                    paste0('g', as.character(year), 1,\n",
    "                                           tolower(states$stateAbrev[i]),\n",
    "                                           '.csv')), col_names = FALSE)\n",
    "    geos <- rbind(geos, geos_temp)\n",
    "    rm(geos_temp) \n",
    "}\n",
    "rm(i)\n",
    "\n",
    "## Load ACS tables, for sub-state geographies\n",
    "acs <- data.frame()\n",
    "for (i in 1:nrow(states)){\n",
    "    temp <- tempfile()\n",
    "    path <- file.path(acsDrive,\n",
    "                      summaryFileFolder,\n",
    "                      gsub(\" \", \"\", states$stateName[i], fixed = TRUE), \n",
    "                      paste0(as.character(year), 1,\n",
    "                             tolower(states$stateAbrev[i]), \n",
    "                             stri_pad_left(sequence, 4, pad = '0'), \n",
    "                             '000', '.zip'))\n",
    "    download.file(path, destfile = temp) \n",
    "    acs_temp <- read_csv(unz(temp,\n",
    "                             paste0('e', as.character(year), '1', \n",
    "                                    tolower(states$stateAbrev[i]), \n",
    "                                    stri_pad_left(sequence, 4, pad = '0'), \n",
    "                                    '000', '.txt')),\n",
    "                         col_names = FALSE) acs <- rbind(acs, acs_temp)\n",
    "    rm(acs_temp)\n",
    "    unlink(temp) \n",
    "}\n",
    "rm(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the code should run without any changes except for the following: When merging the geography names and the ACS data for sub-state geographies, merge the data frames on both the STUSAB (state abreviation) and LOGRECNO (logical record number) fields rather than just the LOGRECNO field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Merge geos and acs data, sub-state geographies\n",
    "incomes <- merge(geos, \n",
    "                 acs[, c('STUSAB', 'LOGRECNO', acsVars)], \n",
    "                 by = c('STUSAB', 'LOGRECNO'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
